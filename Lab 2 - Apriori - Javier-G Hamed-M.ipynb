{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a 'Antonio Javier González Ferrer & Hamed Mohammadpour' -v -d -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will study the problem of discovering association rules between itemsets in a sales transaction database. There are two principal subproblems to solve:\n",
    "\n",
    "1. Finding frequent itemsets with support at least $s$.\n",
    "2. Generating association rules with confidence at least $c$ from the itemsets found in the first step.\n",
    "\n",
    "Therefore, the ultimate goal is to find association rules $X \\rightarrow Y$, where $X$ and $Y$ are itemsets such that $X \\cap Y = \\emptyset$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "    \n",
    "from apriori.utility import create_items_catalog, printify\n",
    "from apriori.itemset import Itemset\n",
    "from apriori.rule import generate_association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explain how the frequent itemsets are calculated with a little example. In this case, our shopping list consists of three different baskets, where each of them contains different elements. We will use letters for representing the elements and numbers for representing baskets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'c'], ['a', 'b', 'e'], ['c', 'd']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets = [['a', 'b', 'c'], ['a', 'b', 'e'], ['c', 'd']]\n",
    "n = len(baskets)\n",
    "baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the basket number $0$ contains the elements $a$, $b$ and $c$. An element $i$ is said to be \"frequent\" if it appears in more than a certain number of baskets. We call this count the support $s(i)$ and we measure it proportionally to the total numbers of transactions. For instance, $s(a) = 2/3$ since it appears in two out of the three baskets. If we would set a support threshold of $0.5$, then we would say that $a$ is a frequent itemset of size $1$.\n",
    "\n",
    "We can also calculate frequent itemsets of any size $k$. Let us focus on calculating frequent itemsets of size $k=2$ for the sake of simplicity. A näive algorithm would count first the frequent itemsets of size $1$, then combinate all different pairs from the previous set and count again the occurrences of the itemsets of size $2$ within the baskets. Considering that we have to check the number of appearances for each pair (which is the most costly operation), there are two main drawbacks in terms of efficiency using this approach:\n",
    "\n",
    "1. We do not need to iterate over the whole dataset again for calculating the support of the pairs, since we could have stored the number of occurrences of each element in a clever way in the first pass. We will explain it soon but the method `create_items_catalog()` saves for each item the list of baskets where it appears (do you already realise how to use this information for calculating the support of 2-itemsets?).\n",
    "\n",
    "2. The <i>apriori</i> property: each subset of a frequent itemset $k$ must be also a frequent itemset. Imagine we generate the tuple $(a,b,c)$ given that the frequent itemsets of size $2$ are $\\{(a,b), (b,c)\\}$. The tuple $(a,b,c)$ cannot belong to the frequent itemsets of size $3$ since its subset $(a,c)$ is not a frequent itemset of size 2. Therefore, a bruce force generation of candidate frequent itemsets is not efficient. We will handle this generation with the implementation of the `generate_candidates()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Store of Support\n",
    "\n",
    "The key idea is to pass over the dataset only once and store for each of the items a list of baskets where it appears. This implicitly indicates the support of an element just by dividing the length of its list by the total number of baskets. Using this information, we can trivially calculate the support of an element of size $k$. We just need to intersect the $k$ different lists and the length of the resulting set will be the final support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'d': [2], 'b': [0, 1], 'a': [0, 1], 'e': [1], 'c': [0, 2]})\n"
     ]
    }
   ],
   "source": [
    "items_catalog = create_items_catalog(baskets, 'str')\n",
    "print(items_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the element $a$ is in the lists $0$ and $1$ and the element $c$ in the lists $0$ and $2$, then $s(a)=s(c)=2/3$. Hence, if we want to calculate the support of the itemset $(a, c)$ we just need to intersect both lists and see the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intersection of (a,c) is {0} and the support is 1/3.\n"
     ]
    }
   ],
   "source": [
    "ac_intersection = set(items_catalog['a']).intersection(set(items_catalog['c']))\n",
    "ac_occurrences = len(ac_intersection)\n",
    "print(\"The intersection of (a,c) is {} and the support is {}/{}.\".format(ac_intersection, ac_occurrences, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Candidate Itemsets\n",
    "\n",
    "The candidates itemsets of size $k$ are generated by combining the frequent itemsets of size $k-1$ and the singletons (frequent itemsets of size $1$). However, each candidate itemset must fulfil the <i>apriori</i> property. Let us compare the brute force method against the implemented method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brute_force_candidates(L2, L1):\n",
    "    brute_force_candidates = set()\n",
    "    for candidate in L2:\n",
    "        for single in L1:\n",
    "            k_candidate = frozenset(candidate.union(single))\n",
    "            if len(k_candidate) == 3:\n",
    "                brute_force_candidates.add(k_candidate)\n",
    "    return brute_force_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# After pruning itemsets, these meet the support threshold...\n",
    "L2 = [set({'a', 'b'}), set({'a', 'c'}), set({'b', 'c'}), set({'b', 'd'})]\n",
    "\n",
    "brute_force_candidates = generate_brute_force_candidates(L2, L1)\n",
    "apriori_candidates = Itemset().generate_candidates(L2, L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brute force candidates are: \n",
      "{(a, d, c), (b, a, c), (b, d, c), (b, a, d)}\n",
      "\n",
      "The candidates generated by the apriori algorithm are: \n",
      "{(b, a, c)}\n"
     ]
    }
   ],
   "source": [
    "print('The brute force candidates are: \\n{}\\n'.format(printify(brute_force_candidates, 4)))\n",
    "print('The candidates generated by the apriori algorithm are: \\n{}'.format(printify(apriori_candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the only valid itemset of size $k=3$ is $(a,b,c)$ since $(a,b), (a,c)$ and $(b,c)$ are also frequent itemsets. For instance, $(a, d, b)$ contains $(a,d)$ which is not a frequent itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Example\n",
    "\n",
    "Now let us test the implementation of the apriori algorithm and generation of associtiation rules with a real example. The following dataset is a sale transaction dataset and was generated from the IBM Almaden Quest research group and can be downloaded from [here](http://fimi.ua.ac.be/data/T10I4D100K.dat). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 100,000 baskets.\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./data/T10I4D100K.dat\"\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    content = f.read()\n",
    "    baskets = []\n",
    "\n",
    "    for line in content.splitlines():\n",
    "        baskets.append(line.split())\n",
    "\n",
    "print(\"The dataset contains {:,} baskets.\".format(len(baskets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining support threshold and Itemset class\n",
    "Let us consider that an itemset is frequent is its support is bigger than 0.01 (that is it appears in, at least, 1% of the transactions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 0.01\n",
    "itemset = Itemset(baskets, support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the items catalog from the baskets. Recall that this object will contain for each individual item a list of baskets where the item appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 870 different items.\n",
      "CPU times: user 516 ms, sys: 0 ns, total: 516 ms\n",
      "Wall time: 516 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "items_catalog = create_items_catalog(baskets)\n",
    "items_length = len(list(items_catalog.keys()))\n",
    "\n",
    "print(\"There are {} different items.\".format(items_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singletons (frequent itemsets k=1)\n",
    "We introduce the following notation. The set $C_k$ contains the candidate itemsets of size $k$, whereas the set $L_k$ contains the actual frequent itemsets of size $k$. In the next step, we calculate which elements of size $1$ are actually frequent itemsets, i.e. those who meet the specified support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 375 frequent itemsets of size k=1.\n",
      "CPU times: user 108 ms, sys: 0 ns, total: 108 ms\n",
      "Wall time: 107 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "frequent_itemsets = set()\n",
    "c1 = {frozenset({x}) for x in set(items_catalog.keys())}\n",
    "l1, _ = itemset.prune_candidates(c1, items_catalog)\n",
    "print(\"There are {} frequent itemsets of size k=1.\".format(len(l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these elements are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(746), (914), (55), (10), (334), (722), (25), (577), (634), (809)}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(l1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate itemsets and prunning\n",
    "From those singletons, let us see how many candidate itemsets of size $k=2$ we find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70125 possible candidate itemsets of size k=2.\n",
      "CPU times: user 316 ms, sys: 4 ms, total: 320 ms\n",
      "Wall time: 319 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c2 = itemset.generate_candidates(l1, l1)\n",
    "print(\"There are {} possible candidate itemsets of size k=2.\".format(len(c2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to find the support of those elements and filter out the ones that do not fulfill the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 frequent itemsets of size k=2.\n",
      "CPU times: user 23.4 s, sys: 4 ms, total: 23.4 s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "l2, _ = itemset.prune_candidates(c2, items_catalog)\n",
    "print(\"There are {} frequent itemsets of size k=2.\".format(len(l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(682, 368), (722, 390), (825, 39), (789, 829), (390, 227), (829, 368), (825, 704), (346, 217), (39, 704)}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(l2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting candidate pairs is the operation that takes most of the time within the algorithm. The `items_catalog` idea improves the performance time, but still it needs to check the intersection of the two lists for each candidate. In the appendix, we propose an alternative method that improves the time complexity at the expense of making the space complexity worse.\n",
    "\n",
    "In practice, for larger $k$ sets the possible combinations are much smaller. We expect to find more frequent pairs than frequent triples, more frequent triples than frequent quadruples, and so on. Therefore, the rest of the algorithm should be fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 possible candidate itemset of size k=3.\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c3 = itemset.generate_candidates(l2, l1)\n",
    "print(\"There is {} possible candidate itemset of size k=3.\".format(len(c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 frequent itemset of size k=3.\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 4.83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l3, _ = itemset.prune_candidates(c3, items_catalog)\n",
    "print(\"There is {} frequent itemset of size k=3.\".format(len(l3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(825, 39, 704)}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(l3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one: Finding k frequent itemsets with support at least s \n",
    "Finally, we can do the whole process automaticall, that is, without specifying the values of $k$ by hand, just by calling the object `itemset` with the method `run`. This method returns:\n",
    "\n",
    "1. `frequent_itemsets` dictionary where the keys indicates the frequent itemsets of size $k$.\n",
    "2. `support_itemsets` containing the support of each of the frequent itemsets. \n",
    "\n",
    "The last variable will be used for calculating the association rules in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate catalog: 0.5095770359039307\n",
      "Generate catalog: 0.5095770359039307\n",
      "Generate catalog: 0.5095770359039307\n",
      "k=1: Candidates generation takes: 0.0021245479583740234\n",
      "k=1: Candidates generation takes: 0.0021245479583740234\n",
      "k=1: Candidates generation takes: 0.0021245479583740234\n",
      "k=1: Prune takes: 0.10056662559509277\n",
      "k=1: Prune takes: 0.10056662559509277\n",
      "k=1: Prune takes: 0.10056662559509277\n",
      "k=1: Ck=870 and Lk=375\n",
      "k=1: Ck=870 and Lk=375\n",
      "k=1: Ck=870 and Lk=375\n",
      "k=2: Candidates generation takes: 0.3604729175567627\n",
      "k=2: Candidates generation takes: 0.3604729175567627\n",
      "k=2: Candidates generation takes: 0.3604729175567627\n",
      "k=2: Prune takes: 24.094606161117554\n",
      "k=2: Prune takes: 24.094606161117554\n",
      "k=2: Prune takes: 24.094606161117554\n",
      "k=2: Ck=70125 and Lk=9\n",
      "k=2: Ck=70125 and Lk=9\n",
      "k=2: Ck=70125 and Lk=9\n",
      "k=3: Candidates generation takes: 0.01285099983215332\n",
      "k=3: Candidates generation takes: 0.01285099983215332\n",
      "k=3: Candidates generation takes: 0.01285099983215332\n",
      "k=3: Prune takes: 0.0038061141967773438\n",
      "k=3: Prune takes: 0.0038061141967773438\n",
      "k=3: Prune takes: 0.0038061141967773438\n",
      "k=3: Ck=1 and Lk=1\n",
      "k=3: Ck=1 and Lk=1\n",
      "k=3: Ck=1 and Lk=1\n",
      "k=4: Candidates generation takes: 0.0009028911590576172\n",
      "k=4: Candidates generation takes: 0.0009028911590576172\n",
      "k=4: Candidates generation takes: 0.0009028911590576172\n",
      "k=4: Prune takes: 2.47955322265625e-05\n",
      "k=4: Prune takes: 2.47955322265625e-05\n",
      "k=4: Prune takes: 2.47955322265625e-05\n",
      "k=4: Ck=0 and Lk=0\n",
      "k=4: Ck=0 and Lk=0\n",
      "k=4: Ck=0 and Lk=0\n"
     ]
    }
   ],
   "source": [
    "support = 0.01\n",
    "itemset = Itemset(baskets, support)\n",
    "frequent_itemsets, support_itemsets = itemset.run(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us print some frequent itemsets of size $k=1,2 $ and $3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(746), (914), (55), (10), (334), (722), (25), (577), (634), (809)}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(682, 368), (722, 390), (825, 39), (789, 829), (390, 227), (829, 368), (825, 704), (346, 217), (39, 704)}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[2], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(825, 39, 704)}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[3], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[4], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little description about how to generate association rules here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the largest $k$-frequent itemset from the last example and calculate the rules generated by it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generation_rules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2f02b577148d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk_itemset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneration_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_itemset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_itemsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generation_rules' is not defined"
     ]
    }
   ],
   "source": [
    "c = 0.5\n",
    "k_itemset = next(iter(l3))\n",
    "rules = generation_rules(c, k_itemset, support_itemsets)\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
