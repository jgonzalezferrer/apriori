{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a 'Antonio Javier González Ferrer & Hamed Mohammadpour' -v -d -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will study the problem of discovering association rules between itemsets in a sales transaction database. There are two principal subproblems to solve:\n",
    "\n",
    "1. Finding frequent itemsets with support at least $s$.\n",
    "2. Generating association rules with confidence at least $c$ from the itemsets found in the first step.\n",
    "\n",
    "Therefore, the ultimate goal is to find association rules $X \\rightarrow Y$, where $X$ and $Y$ are itemsets such that $X \\cap Y = \\emptyset$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "    \n",
    "from apriori.utility import create_items_catalog, printify\n",
    "from apriori.itemset import Itemset\n",
    "from apriori.association_rule import AssociationRule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explain how the frequent itemsets are calculated with a little example. In this case, our shopping list consists of three different baskets, where each of them contains different elements. We will use letters for representing the elements and numbers for representing baskets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'c'], ['a', 'b', 'e'], ['c', 'd']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets = [['a', 'b', 'c'], ['a', 'b', 'e'], ['c', 'd']]\n",
    "n = len(baskets)\n",
    "baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the basket number $0$ contains the elements $a$, $b$ and $c$. An element $i$ is said to be \"frequent\" if it appears in more than a certain number of baskets. We call this count the support $s(i)$ and we measure it proportionally to the total numbers of transactions. For instance, $s(a) = 2/3$ since it appears in two out of the three baskets. If we would set a support threshold of $0.5$, then we would say that $a$ is a frequent itemset of size $1$.\n",
    "\n",
    "We can also calculate frequent itemsets of any size $k$. Let us focus on calculating frequent itemsets of size $k=2$ for the sake of simplicity. A näive algorithm would count first the frequent itemsets of size $1$, then combinate all different pairs from the previous set and count again the occurrences of the itemsets of size $2$ within the baskets. Considering that we have to check the number of appearances for each pair (which is the most costly operation), there are two main drawbacks in terms of efficiency using this approach:\n",
    "\n",
    "1. We do not need to iterate over the whole dataset again for calculating the support of the pairs, since we could have stored the number of occurrences of each element in a clever way in the first pass. We will explain it soon but the method `create_items_catalog()` saves for each item the list of baskets where it appears (do you already realise how to use this information for calculating the support of 2-itemsets?).\n",
    "\n",
    "2. The <i>apriori</i> property: each subset of a frequent itemset $k$ must be also a frequent itemset. Imagine we generate the tuple $(a,b,c)$ given that the frequent itemsets of size $2$ are $\\{(a,b), (b,c)\\}$. The tuple $(a,b,c)$ cannot belong to the frequent itemsets of size $3$ since its subset $(a,c)$ is not a frequent itemset of size 2. Therefore, a bruce force generation of candidate frequent itemsets is not efficient. We will handle this generation with the implementation of the `generate_candidates()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Store of Support\n",
    "\n",
    "The key idea is to pass over the dataset only once and store for each of the items a list of baskets where it appears. This implicitly indicates the support of an element just by dividing the length of its list by the total number of baskets. Using this information, we can trivially calculate the support of an element of size $k$. We just need to intersect the $k$ different lists and the length of the resulting set will be the final support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'a': [0, 1], 'e': [1], 'b': [0, 1], 'd': [2], 'c': [0, 2]})\n"
     ]
    }
   ],
   "source": [
    "items_catalog = create_items_catalog(baskets, 'str')\n",
    "print(items_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the element $a$ is in the lists $0$ and $1$ and the element $c$ in the lists $0$ and $2$, then $s(a)=s(c)=2/3$. Hence, if we want to calculate the support of the itemset $(a, c)$ we just need to intersect both lists and see the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intersection of (a,c) is {0} and the support is 1/3.\n"
     ]
    }
   ],
   "source": [
    "ac_intersection = set(items_catalog['a']).intersection(set(items_catalog['c']))\n",
    "ac_occurrences = len(ac_intersection)\n",
    "print(\"The intersection of (a,c) is {} and the support is {}/{}.\".format(ac_intersection, ac_occurrences, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Candidate Itemsets\n",
    "\n",
    "The candidates itemsets of size $k$ are generated by combining the frequent itemsets of size $k-1$ and the singletons (frequent itemsets of size $1$). However, each candidate itemset must fulfil the <i>apriori</i> property. Let us compare the brute force method against the implemented method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brute_force_candidates(L2, L1):\n",
    "    brute_force_candidates = set()\n",
    "    for candidate in L2:\n",
    "        for single in L1:\n",
    "            k_candidate = frozenset(candidate.union(single))\n",
    "            if len(k_candidate) == 3:\n",
    "                brute_force_candidates.add(k_candidate)\n",
    "    return brute_force_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# After pruning itemsets, these meet the support threshold...\n",
    "L2 = [set({'a', 'b'}), set({'a', 'c'}), set({'b', 'c'}), set({'b', 'd'})]\n",
    "\n",
    "brute_force_candidates = generate_brute_force_candidates(L2, L1)\n",
    "apriori_candidates = Itemset().generate_candidates(L2, L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brute force candidates are: \n",
      "{(b, a, c), (b, d, c), (b, d, a), (a, d, c)}\n",
      "\n",
      "The candidates generated by the apriori algorithm are: \n",
      "{(b, a, c)}\n"
     ]
    }
   ],
   "source": [
    "print('The brute force candidates are: \\n{}\\n'.format(printify(brute_force_candidates, 4)))\n",
    "print('The candidates generated by the apriori algorithm are: \\n{}'.format(printify(apriori_candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the only valid itemset of size $k=3$ is $(a,b,c)$ since $(a,b), (a,c)$ and $(b,c)$ are also frequent itemsets. For instance, $(a, d, b)$ contains $(a,d)$ which is not a frequent itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Example\n",
    "\n",
    "Now let us test the implementation of the apriori algorithm and generation of associtiation rules with a real example. The following dataset is a sale transaction dataset and was generated from the IBM Almaden Quest research group and can be downloaded from [here](http://fimi.ua.ac.be/data/T10I4D100K.dat). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 100,000 baskets.\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./data/T10I4D100K.dat\"\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    content = f.read()\n",
    "    baskets = []\n",
    "\n",
    "    for line in content.splitlines():\n",
    "        baskets.append(line.split())\n",
    "\n",
    "print(\"The dataset contains {:,} baskets.\".format(len(baskets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining support threshold and Itemset class\n",
    "Let us consider that an itemset is frequent is its support is bigger than 0.01 (that is it appears in, at least, 1% of the transactions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 0.01\n",
    "itemset = Itemset(baskets, support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the items catalog from the baskets. Recall that this object will contain for each individual item a list of baskets where the item appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 870 different items.\n",
      "CPU times: user 476 ms, sys: 8 ms, total: 484 ms\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "items_catalog = create_items_catalog(baskets)\n",
    "items_length = len(list(items_catalog.keys()))\n",
    "\n",
    "print(\"There are {} different items.\".format(items_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singletons (frequent itemsets k=1)\n",
    "We introduce the following notation. The set $C_k$ contains the candidate itemsets of size $k$, whereas the set $L_k$ contains the actual frequent itemsets of size $k$. In the next step, we calculate which elements of size $1$ are actually frequent itemsets, i.e. those who meet the specified support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 375 frequent itemsets of size k=1.\n",
      "CPU times: user 88 ms, sys: 0 ns, total: 88 ms\n",
      "Wall time: 88.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "frequent_itemsets = set()\n",
    "c1 = {frozenset({x}) for x in set(items_catalog.keys())}\n",
    "l1, _ = itemset.prune_candidates(c1, items_catalog)\n",
    "print(\"There are {} frequent itemsets of size k=1.\".format(len(l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these elements are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(349), (789), (653), (862), (490), (884), (151), (746), (579), (422)}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(l1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate candidate itemsets and prunning\n",
    "From those singletons, let us see how many candidate itemsets of size $k=2$ we find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70125 possible candidate itemsets of size k=2.\n",
      "CPU times: user 324 ms, sys: 0 ns, total: 324 ms\n",
      "Wall time: 323 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c2 = itemset.generate_candidates(l1, l1)\n",
    "print(\"There are {} possible candidate itemsets of size k=2.\".format(len(c2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to find the support of those elements and filter out the ones that do not fulfill the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 frequent itemsets of size k=2.\n",
      "CPU times: user 16.4 s, sys: 16 ms, total: 16.4 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "l2, _ = itemset.prune_candidates(c2, items_catalog)\n",
    "print(\"There are {} frequent itemsets of size k=2.\".format(len(l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(825, 704), (217, 346), (829, 368), (789, 829), (682, 368), (39, 825), (39, 704), (390, 227), (390, 722)}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(l2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting candidate pairs is the operation that takes most of the time within the algorithm. The `items_catalog` idea improves the performance time, but still it needs to check the intersection of the two lists for each candidate. In the appendix, we propose an alternative method that improves the time complexity at the expense of making the space complexity worse.\n",
    "\n",
    "In practice, for larger $k$ sets the possible combinations are much smaller. We expect to find more frequent pairs than frequent triples, more frequent triples than frequent quadruples, and so on. Therefore, the rest of the algorithm should be fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 possible candidate itemset of size k=3.\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 6.16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c3 = itemset.generate_candidates(l2, l1)\n",
    "print(\"There is {} possible candidate itemset of size k=3.\".format(len(c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 frequent itemset of size k=3.\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 4.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l3, _ = itemset.prune_candidates(c3, items_catalog)\n",
    "print(\"There is {} frequent itemset of size k=3.\".format(len(l3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(825, 39, 704)}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(l3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one: Finding k frequent itemsets with support at least s \n",
    "Finally, we can do the whole process automatically, that is, without specifying the values of $k$ by hand, just by calling the object `itemset` with the method `run`. This method returns:\n",
    "\n",
    "1. `frequent_itemsets` dictionary where the keys indicates the frequent itemsets of size $k$.\n",
    "2. `support_itemsets` containing the support of each of the frequent itemsets. \n",
    "\n",
    "The last variable will be used for calculating the association rules in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate catalog: 0.4192075729370117\n",
      "Generate catalog: 0.4192075729370117\n",
      "k=1: Candidates generation takes: 0.001055002212524414\n",
      "k=1: Candidates generation takes: 0.001055002212524414\n",
      "k=1: Prune takes: 0.0733642578125\n",
      "k=1: Prune takes: 0.0733642578125\n",
      "k=1: Ck=870 and Lk=375\n",
      "k=1: Ck=870 and Lk=375\n",
      "k=2: Candidates generation takes: 0.2848320007324219\n",
      "k=2: Candidates generation takes: 0.2848320007324219\n",
      "k=2: Prune takes: 16.243465423583984\n",
      "k=2: Prune takes: 16.243465423583984\n",
      "k=2: Ck=70125 and Lk=9\n",
      "k=2: Ck=70125 and Lk=9\n",
      "k=3: Candidates generation takes: 0.006543159484863281\n",
      "k=3: Candidates generation takes: 0.006543159484863281\n",
      "k=3: Prune takes: 0.002995014190673828\n",
      "k=3: Prune takes: 0.002995014190673828\n",
      "k=3: Ck=1 and Lk=1\n",
      "k=3: Ck=1 and Lk=1\n",
      "k=4: Candidates generation takes: 0.0005066394805908203\n",
      "k=4: Candidates generation takes: 0.0005066394805908203\n",
      "k=4: Prune takes: 1.430511474609375e-05\n",
      "k=4: Prune takes: 1.430511474609375e-05\n",
      "k=4: Ck=0 and Lk=0\n",
      "k=4: Ck=0 and Lk=0\n",
      "Total time: 17.06179690361023\n",
      "Total time: 17.06179690361023\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets, support_itemsets = itemset.run(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us print some frequent itemsets of size $k=1,2 $ and $3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(349), (789), (653), (862), (490), (884), (151), (746), (579), (422)}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(825, 704), (217, 346), (829, 368), (789, 829), (682, 368), (39, 825), (39, 704), (390, 227), (390, 722)}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[2], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(825, 39, 704)}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[3], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printify(frequent_itemsets[4], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have identified the frequent itemsets of a sales transaction given a support threshold $s$, we can generate association rules between them. We need an extra input parameter, the confidence threshold $c$. Given a rule $R: X \\rightarrow Y$, the confidence of $R$ is the fraction of transactions containing $X \\cup Y$ in all transaction that contain $X$. \n",
    "\n",
    "Good news, the confidence of a rule can be defined in terms of supports. For example, given the rule $R_1: \\{a,b\\} \\rightarrow \\{c,d\\}$ the confidence of $R_1$ is calculated as:\n",
    "\n",
    "$$\\displaystyle c(R_1) = \\frac{s(\\{a,b,c,d\\})}{s(\\{a,b\\})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we generate new association rules? For each frequent itemset $I$, we generate a new rule with the form of $I - \\{j\\} \\rightarrow j$ where $j$ is an element of the frequent itemset $I$. We repite this process for each generated rule until: a) the antecedent is empty b) the confidence of the rule is below the threshold level. \n",
    "\n",
    "Thanks to the confidence-based pruning property, if a rule $X \\rightarrow Y$ does not satisfy the confidence threshold, then any rule $X' \\rightarrow Y - X'$ where $X'$ is a subset of $X$, must not satisfy the confidence threshold as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real example\n",
    "\n",
    "Let us take the largest $k$-frequent itemset from the last example and calculate the rules generated by it with a confindence of 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(39, 704)} -> {(825)}\n",
      "{(704)} -> {(39, 825)}\n",
      "{(39, 825)} -> {(704)}\n",
      "{(704, 825)} -> {(39)}\n"
     ]
    }
   ],
   "source": [
    "k_itemset = next(iter(l3))\n",
    "\n",
    "association_rule05 = AssociationRule(0.5, support_itemsets)\n",
    "rules_05 = association_rule05.generate_rules_from_single_itemset(k_itemset)\n",
    "\n",
    "for rule in rules_05:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe how the number of rules retrieved by the algorithm changes when we increase/decrease the confidence threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(39, 704)} -> {(825)}\n",
      "{(39, 825)} -> {(704)}\n",
      "{(704, 825)} -> {(39)}\n"
     ]
    }
   ],
   "source": [
    "association_rule08 = AssociationRule(0.8, support_itemsets)\n",
    "rules_08 = association_rule08.generate_rules_from_single_itemset(k_itemset)\n",
    "\n",
    "for rule in rules_08:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one: Generating all association rules with confidence at least c\n",
    "\n",
    "To conclude this notebook, we create all the rules generated by all the frequent itemsets calculated in the previous section by creating an `AssociationRule` object with the `frequent_itemsets` dictionary and calling the method `generate_all_rules`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(825)} -> {(39)}\n",
      "{(789)} -> {(829)}\n",
      "{(825)} -> {(704)}\n",
      "{(39)} -> {(704, 825)}\n",
      "{(829)} -> {(789)}\n",
      "{(390)} -> {(722)}\n",
      "{(704)} -> {(39, 825)}\n",
      "{(368)} -> {(682)}\n",
      "{(390)} -> {(227)}\n",
      "{(39, 704)} -> {(825)}\n",
      "{(682)} -> {(368)}\n",
      "{(227)} -> {(390)}\n",
      "{(217)} -> {(346)}\n",
      "{(704, 825)} -> {(39)}\n",
      "{(825)} -> {(39, 704)}\n",
      "{(39)} -> {(704)}\n",
      "{(39, 825)} -> {(704)}\n",
      "{(39)} -> {(825)}\n",
      "{(346)} -> {(217)}\n",
      "{(829)} -> {(368)}\n",
      "{(704)} -> {(825)}\n",
      "{(722)} -> {(390)}\n",
      "{(704)} -> {(39)}\n",
      "{(368)} -> {(829)}\n"
     ]
    }
   ],
   "source": [
    "association_rule = AssociationRule(0.1, support_itemsets, frequent_itemsets)\n",
    "rules = association_rule.generate_all_rules()\n",
    "for rule in rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Storing Support of Pairs\n",
    "\n",
    "Lastly, we have decided to try a different approach for calculating the support of the itemsets. Since the candidate itemsets of size $2$ are the most numerous compared to any other $k$, mostly all the computation time will be spent checking the interesection of the two elements within each pair, as already explained (using `items_catalog` dictionary).  We have extended this dictionary and not only include the support of singletons but also the support of pairs. This is created just by simply creating combinations of pairs within each basket, and storing accordingly the list of baskets where that pair appears. \n",
    "\n",
    "The latter solution, of course, will spend more time creating the `items_catalog` but, on the other hand, the pruning step for $k=2$ will be immediately. Let us check the overall time of these two solutions, comparing the functions `create_items_catalog` and  `create_items_catalog_with_pairs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First solution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total time: 18.213627815246582\n",
      "Total time: 18.213627815246582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second solution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total time: 10.310189485549927\n",
      "Total time: 10.310189485549927\n"
     ]
    }
   ],
   "source": [
    "from apriori.utility import create_items_catalog_with_pairs\n",
    "\n",
    "print('First solution:')\n",
    "_, _ = itemset.run(logging.INFO, create_items_catalog)\n",
    "\n",
    "print('Second solution:')\n",
    "_, _ = itemset.run(logging.INFO, create_items_catalog_with_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing running times, we can agree that in spite of the second solution defeats the first proposal, this difference of time is at the expense of increasing the space complexity. However, given smaller values of the support threshold, the second solution becames much more efficient, since the number of candidates pairs considerable increases: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First solution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total time: 127.79799556732178\n",
      "Total time: 127.79799556732178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second solution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total time: 82.53843116760254\n",
      "Total time: 82.53843116760254\n"
     ]
    }
   ],
   "source": [
    "itemset.support_threshold /= 10  # ten times smaller\n",
    "\n",
    "print('First solution:')\n",
    "_, _ = itemset.run(logging.INFO, create_items_catalog)\n",
    "\n",
    "print('Second solution:')\n",
    "_, _ = itemset.run(logging.INFO, create_items_catalog_with_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
