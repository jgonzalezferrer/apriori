{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonio Javier González Ferrer & Hamed Mohammadpour 2017-11-15 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 6.2.1\n",
      "Git repo: https://github.com/jgonzalezferrer/apriori.git\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a 'Antonio Javier González Ferrer & Hamed Mohammadpour' -v -d -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apriori.algorithm import find_frequent_itemsets, generate_candidates, prune_candidates\n",
    "from apriori.utility import create_items_catalog\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import json\n",
    "\n",
    "# For printing maps and dictionaries in sorted, beautiful format\n",
    "def printify(my_dict):\n",
    "    print(json.dumps(my_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explain how the frequent itemsets and association rules are calculated with a little example. Our shopping list consists of three different baskets, where each oen contains different elements. We will use letters for representing the elements and numbers for representing baskets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'c'], ['a', 'b', 'e'], ['c', 'd']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets = [['a', 'b', 'c'], ['a', 'b', 'e'], ['c', 'd']]\n",
    "n = len(baskets)\n",
    "baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basket number $0$ contains the elements $a$, $b$ and $c$. An element $i$ is said to be \"frequent\" if it appears in more than a certain number of baskets. We call this count the support $s(i)$ and we measure it proportionally to the total numbers of transactions. For instance, $s(a) = 2/3$ since it appears in two of the three baskets. \n",
    "\n",
    "We can also calculate frequent itemsets of any size $k$. Let us focus on calculating frequent itemsets of size $k=2$ for the sake of simplicity. A näive algorithm would count first the frequent itemsets of size $1$, then combinate all different pairs from the previous set and count again the occurrences of the itemsets of size $2$ within the baskets. Considering that we have to check the number of appearances of each pair (which is the most costly operation), there are two main drawbacks in terms of efficiency using this approach:\n",
    "\n",
    "1. We do not need to iterate over the whole dataset again for calculating the support of the pairs, since we could have stored the number of occurrences of each element in a clever way in the first pass. We will explain it soon but the method `create_items_catalog()` saves for each item the list of baskets where it appears (do you already realise how to use this information for calculating the support of 2-itemsets?) \n",
    "2. The <i>apriori</i> property: each subset of a frequent itemset $k$ must be also a frequent itemset. Imagine we generate the tuple $(a,b,c)$ given that the frequent itemsets of size $2$ are $\\{(a,b), (b,c)\\}$. The tuple $(a,b,c)$ cannot belong to the frequent itemsets of size $3$ since its subset $(a,c)$ is not a frequent itemset of size 2. Therefore, a bruce force generation of candidate frequent itemsets is not efficient. We will handle this generation with the implementation of the `generate_candidates()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Store of Support\n",
    "\n",
    "The key idea is to pass over the dataset only once and store for each of the items a list of baskets where it appears. This implicitly indicates the support of an element just by dividing the length of its list by the total number of baskets. Using this information, we can trivially calculate the support of an element of size $k$. We just need to intersect the $k$ different lists and the length of the resulting set will be the final support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"b\": [0, 1], \"d\": [2], \"a\": [0, 1], \"e\": [1], \"c\": [0, 2]}\n"
     ]
    }
   ],
   "source": [
    "items_catalog = create_items_catalog(baskets, 'str')\n",
    "printify(items_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the element $a$ is in the lists $0$ and $1$ and the element $c$ in the lists $0$ and $2$, then $s(a)=s(c)=2/3$. Hence, if we want to calculate the support of the itemset $(a, c)$ we just need to intersect both lists and see the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intersection of (a,c) is {0} and the support is 1/3.\n"
     ]
    }
   ],
   "source": [
    "ac_intersection = set(items_catalog['a']).intersection(set(items_catalog['c']))\n",
    "ac_occurrences = len(ac_intersection)\n",
    "print(\"The intersection of (a,c) is {} and the support is {}/{}.\".format(ac_intersection, ac_occurrences, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of Candidate Itemsets\n",
    "\n",
    "The candidates itemsets of size $k$ are generated by combining the frequent itemsets of size $k-1$ and the singletons (frequent itemsets of size $1$). However, each candidate itemset must fulfil the <i>apriori</i> property. Let us compare the brute force method against the implemented method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# after pruning itemsets, these meet the support threshold...\n",
    "L2 = [set({'a', 'b'}), set({'a', 'c'}), set({'b', 'c'}), set({'b', 'd'})] \n",
    "\n",
    "brute_force_candidates = set()\n",
    "for candidate in L2:\n",
    "    for single in L1:\n",
    "        k_candidate = frozenset(candidate.union(single))\n",
    "        if len(k_candidate) == 3:\n",
    "            brute_force_candidates.add(k_candidate)\n",
    "\n",
    "apriori_candidates = generate_candidates(L2, L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brute force candidates are: \n",
      "{frozenset({'b', 'd', 'c'}), frozenset({'b', 'd', 'a'}), frozenset({'d', 'a', 'c'}), frozenset({'b', 'a', 'c'})}\n",
      "\n",
      "The candidates generated by the apriori algorithm are: \n",
      "{frozenset({'b', 'a', 'c'})}\n"
     ]
    }
   ],
   "source": [
    "print('The brute force candidates are: \\n{}\\n'.format(brute_force_candidates))\n",
    "print('The candidates generated by the apriori algorithm are: \\n{}'.format(apriori_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the only valid itemset of size $k=3$ is $(a,b,c)$ since $(a,b), (a,c)$ and $(b,c)$ are also frequent itemsets. For instance, $(a, d, b)$ contains $(a,d)$ which is not a frequent itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Example\n",
    "\n",
    "Now let us test is with a real example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 100,000 baskets.\n",
      "There are 870 different items.\n",
      "CPU times: user 604 ms, sys: 8 ms, total: 612 ms\n",
      "Wall time: 611 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_file = \"./data/T10I4D100K.dat\"\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    content = f.read()\n",
    "    baskets = []\n",
    "\n",
    "    for line in content.splitlines():\n",
    "        baskets.append(line.split())\n",
    "\n",
    "support = 0.01\n",
    "n = len(baskets)\n",
    "print(\"The dataset contains {:,} baskets.\".format(n))\n",
    "\n",
    "items_catalog = create_items_catalog(baskets)\n",
    "items_length = len(list(items_catalog.keys()))\n",
    "print(\"There are {} different items.\".format(items_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate which elements of size 1 are actually frequent itemsets, i.e. those who meet the specified support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 375 frequent itemsets of size k=1.\n",
      "CPU times: user 80 ms, sys: 4 ms, total: 84 ms\n",
      "Wall time: 83.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "frequent_itemsets = set()\n",
    "c1 = {frozenset({x}) for x in set(items_catalog.keys())}\n",
    "l1, _ = prune_candidates(n, c1, support, items_catalog)\n",
    "print(\"There are {} frequent itemsets of size k=1.\".format(len(l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From those singletons, let us see how many candidate itemsets we find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70125 possible candidate itemsets of size k=2.\n",
      "CPU times: user 260 ms, sys: 20 ms, total: 280 ms\n",
      "Wall time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c2 = generate_candidates(l1, l1)\n",
    "print(\"There are {} possible candidate itemsets of size k=2.\".format(len(c2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to find the support of those elements and filter out the ones that do not fulfill the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 frequent itemsets of size k=2.\n",
      "CPU times: user 16.2 s, sys: 12 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "l2, _ = prune_candidates(n, c2, support, items_catalog)\n",
    "print(\"There are {} frequent itemsets of size k=2.\".format(len(l2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the operation that takes most of the time since it needs to check many candidate itemsets. For larger $k$ the possible combinations are much smaller and therefore it will be fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 possible candidate itemset of size k=3.\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c3 = generate_candidates(l2, l1)\n",
    "print(\"There is {} possible candidate itemset of size k=3.\".format(len(c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 frequent itemset of size k=3 and it is -> {frozenset({frozenset({'39'}), frozenset({'825'}), frozenset({'704'})})}\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 4.73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l3, _ = prune_candidates(n, c3, support, items_catalog)\n",
    "print(\"There is {} frequent itemset of size k=3 and it is -> {}\".format(len(l3), l3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
