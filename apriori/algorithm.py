import itertools
import collections
import time

from apriori.rule import Rule
from apriori.utility import create_items_catalog, create_items_catalog_with_itemsets


def create_items(baskets):
    """
    Given a set of baskets, create unique set of singleton elements.

    :param baskets:
    :return:
    """
    items = set()
    for item in baskets.keys():
        if len(item) == 1:
            items.add(frozenset({item}))
    return items


def generate_candidates(prev_candidates, singletons):
    """
   Candidates in Ck can be generated by combining itemsets from Lk-1 and singletons from L1.

    One should be careful and selective with candidate generation: for a candidate in Ck to be a frequent itemset,
    all its subsets must be frequent, not only the itemsets from Lk-1 and L1 that the candidate is constructed from,
    i.e., each of its subsets should be in the corresponding Lm, m = 1,â€¦, k-1
   :param prev_candidates:
   :param singletons:
   :return:
   """
    k = len(next(iter(prev_candidates)))+1  # Extract size of an element from prev to calculate the current iteration.

    m = k - 2 if k > 1 else 0  # Base case k = 1, ignore: used for check subsets are frequent itemsets.
    candidates = set()

    for candidate in prev_candidates:
        for i in singletons:
            mismatch = False
            new_candidate = frozenset(candidate).union(i)
            for combination in itertools.combinations(candidate, m):
                frequent_tuple = frozenset(combination).union(i)
                if frequent_tuple not in prev_candidates:
                    mismatch = True
                    break
            if not mismatch and len(new_candidate) == k: candidates.add(new_candidate)

    return candidates


def prune_candidates(n, candidates, s, items_catalog):

    occurrences = collections.Counter()

    for candidate in candidates:
        if len(items_catalog[candidate]) > 0:
            occurrences[candidate] = len(items_catalog[candidate])
        else:
            baskets_intersection = []
            for item in candidate:
                baskets_intersection.append(set(items_catalog[item]))
            occurrences[candidate] = len(set.intersection(*baskets_intersection))


    candidates_return = candidates.copy()
    support_return = dict()
    for candidate, occurrence in occurrences.items():
        support = occurrence/n
        if support < s:
            candidates_return.discard(candidate)

        support_return[candidate] = support
    return candidates_return, support_return


def find_frequent_itemsets(n, support, items_catalog):
    frequent_itemsets = set()
    support_itemsets = dict()

    c1 = {frozenset({x}) for x in set(filter(lambda x: len(x) == 1, items_catalog.keys()))}
    l1, support_l1 = prune_candidates(n, c1, support, items_catalog)

    frequent_itemsets = frequent_itemsets.union(l1)
    support_itemsets.update(support_l1)

    current = l1

    while len(current) > 0:
        time_ck = time.time()
        ck = generate_candidates(current, l1)
        print('Candidates generation takes: {}'.format(time.time()-time_ck))

        time_lk = time.time()
        lk, support_lk = prune_candidates(n, ck, support, items_catalog)
        print('Prune takes: {}'.format(time.time()-time_lk))

        frequent_itemsets = frequent_itemsets.union(lk)
        support_itemsets.update(support_lk)
        current = lk

        print('Ck={} and Lk={}'.format(len(ck), len(lk)))

    return frequent_itemsets, support_itemsets


def generation_rules(c, itemset, support_itemset):
    def _generation_rules(candidate_rule):
        if len(candidate_rule.antecedent) == 0:
            return

        if candidate_rule.confidence >= c or len(candidate_rule.consequent) == 0:  # second condition for {a,b,c} -> {}
            if len(candidate_rule.consequent) > 0: rules.add(candidate_rule)

            for i in candidate_rule.antecedent:
                new_antecedent = candidate_rule.antecedent.difference({i})
                new_consequent = candidate_rule.consequent.union({i})
                if len(new_antecedent) == 0:  # next iteration -> {} -> {a,b,c}
                    new_confidence = 0
                else:
                    new_confidence = support_itemset[new_antecedent.union(new_consequent)] / support_itemset[new_antecedent]

                _generation_rules(Rule(new_antecedent, new_consequent, new_confidence))
        return

    candidate_rule = Rule(itemset)
    rules = set()
    _generation_rules(candidate_rule)

    return rules


if __name__ == "__main__":
    filename = '../data/T10I4D100K.dat'
    with open(filename, 'r') as f:
        content = f.read()

        baskets = []
        for line in content.splitlines():
            baskets.append(line.split())

        time999 = time.time()
        items_catalog = create_items_catalog_with_itemsets(baskets)
        print("Generate catalog: {}".format(time.time()-time999))
        support = 0.01
        n = len(baskets)
        frequent_itemsets, support_itemsets = find_frequent_itemsets(n, support, items_catalog)
        print(len(frequent_itemsets))
        #
        from apyori import apriori

        results = list(apriori(baskets, min_support=0.01))

        print(results)
        print(len(results))

        # next_candidates = [
        #     candidate for candidate in tmp_next_candidates
        #     if all(
        #         True if frozenset(x) in prev_candidates else False
        #         for x in combinations(candidate, length - 1))
        #     ]